{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Likithasravani/Likithasravani/blob/main/Copy_of_README.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PzeiEeWrRe4",
        "lang": "es"
      },
      "source": [
        "# Aventuras con texto"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4mukIik_e0hV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E8dR-WK0e1Og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YeTxx3FzfGd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "x-ecsyUhXPUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets"
      ],
      "metadata": {
        "id": "8NgyvEQTXn2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wine = datasets.load_wine()\n",
        "\n",
        "print(wine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ev_Hea6XzHw",
        "outputId": "f798ac97-1b62-4bea-e9da-477eaf1adfc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
            "        1.065e+03],\n",
            "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
            "        1.050e+03],\n",
            "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
            "        1.185e+03],\n",
            "       ...,\n",
            "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
            "        8.350e+02],\n",
            "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
            "        8.400e+02],\n",
            "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
            "        5.600e+02]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2]), 'frame': None, 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'), 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n', 'feature_names': ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.DataFrame(wine['data'])\n",
        "\n",
        "print(X.head())\n",
        "\n",
        "print(wine.data.shape)\n",
        "\n",
        "#print the wine labels (0:Class_0, 1:class_2, 2:class_2)\n",
        "\n",
        "y=print (wine.target)"
      ],
      "metadata": {
        "id": "r7-QtlbEeWOY",
        "outputId": "d675ce40-c191-4d39-dd81-00f63b893160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0     1     2     3      4     5     6     7     8     9     10    11  \\\n",
            "0  14.23  1.71  2.43  15.6  127.0  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
            "1  13.20  1.78  2.14  11.2  100.0  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
            "2  13.16  2.36  2.67  18.6  101.0  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
            "3  14.37  1.95  2.50  16.8  113.0  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
            "4  13.24  2.59  2.87  21.0  118.0  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
            "\n",
            "       12  \n",
            "0  1065.0  \n",
            "1  1050.0  \n",
            "2  1185.0  \n",
            "3  1480.0  \n",
            "4   735.0  \n",
            "(178, 13)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Features: \", wine.feature_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1szyxWF4X7E6",
        "outputId": "a4066c3f-790b-4610-c1ff-5f9b1fde88c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hF0ytG4waL1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Labels: \", wine.target_names)"
      ],
      "metadata": {
        "id": "wW12O6_BdElU",
        "outputId": "7b17e123-50f9-4a92-ac74-6fef7c8e6876",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels:  ['class_0' 'class_1' 'class_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO8i-JFfrRe6",
        "lang": "en"
      },
      "source": [
        "# Adventures with text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v-r_MnQrRe7",
        "lang": "es"
      },
      "source": [
        "Aquí tienes unos *notebooks* que he creado en Jupyter (tanto en español como en inglés) para acompañar las clases que doy en un máster de Inteligencia Artificial sobre los últimos desarrollos en PNL (procesamiento del lenguaje natural o NLP en las siglas inglesas) con redes neuronales.\n",
        "<!--more-->\n",
        "\n",
        "Se dice que 2018 fue el año \"ImageNet\" para texto. Se refiere a los avances en el reconocimiento de imágenes y, en particular, a *transfer learning*. Es decir, la posibilidad de entrenar un modelo grande, computacionalmente costoso con un conjunto de datos generales, y poder \"tunear\" este modelo para una tarea específica (por ejemplo, diferenciar entre perros y gatos). Hasta hace poco, no era factible aplicar transfer learning a modelos basados en texto (o PNL).\n",
        "\n",
        "* [Referencias](https://github.com/teticio/aventuras-con-textos/blob/master/Referencias.ipynb). Una lista de enlaces a todos los trabajos académicos relevantes.\n",
        "* [Clasificación de texto con modelos de última generación](https://github.com/teticio/aventuras-con-textos/blob/master/Clasificacion_de_texto_con_modelos_de_ultima_generacion.ipynb). Una introducción y comparación entre los modelos Word2Vec, ELMo, BERT y XLNet para clasificar reseñas de películas IMDB como positivas o negativas.\n",
        "* [Atención](https://github.com/teticio/aventuras-con-textos/blob/master/Atencion.ipynb). Una mirada en  profundidad al mecanismo de atención utilizado en el Transformador, el componente principal de BERT, partiendo de un simple modelo Vec2Vec para traducir del inglés al español.\n",
        "* [BERT entiende](https://github.com/teticio/aventuras-con-textos/blob/master/BERT_entiende.ipynb). Aquí usamos un modelo BERT que se ha tuneado con la tarea SQuAD (conjunto de datos de respuesta a preguntas de Stanford) para responder a preguntas de comprensión de lectura sobre un libro de Harry Potter.\n",
        "* [BERT predice](https://github.com/teticio/aventuras-con-textos/blob/master/BERT_predice.ipynb). BERT está entrenado para poder completar las palabras que faltan en una frase.\n",
        "* [Bertle](https://github.com/teticio/aventuras-con-textos/blob/master/Bertle.ipynb). Un motor de búsqueda semántico que utiliza *embeddings* a nivel de frase de BERT para encontrar artículos relevantes de Stack Overflow.\n",
        "* [Dr. BERT](https://github.com/teticio/aventuras-con-textos/blob/master/Dr_Bert.ipynb). Un psicoanalista inspirado en [Eliza](http://psych.fullerton.edu/mbirnbaum/psych101/Eliza.htm) y entrenado usando las transcripciones del Dr. Carl Rogers.\n",
        "* [Modelos de lenguaje](https://github.com/teticio/aventuras-con-textos/blob/master/Modelos_de_lenguaje.ipynb). Un modelo de lenguaje es una función que estima la probabilidad de la siguiente palabra (o *token*) condicionada en el texto que la precede. Aquí vamos a utilizar el modelo de lenguaje GPT-2 para predecir la continuación de una frase y destacar construcciones poco probables.\n",
        "* [Generación de texto con modelos de última generación](https://github.com/teticio/aventuras-con-textos/blob/master/Modelos_generativos_de_texto_de_ultima_generacion.ipynb). Los modelos de lenguaje XLNet y GPT-2 se utilizan para generar una prosa aleatoria, desde escribir capítulos de Game of Thrones hasta generar tweets al estilo de Donald [Trump](https://twitter.com/realDonTrumpy).\n",
        "* [Opiniones de Amazon](https://github.com/teticio/aventuras-con-textos/blob/master/Amazon_Opiniones.ipynb). Una competición de estilo Kaggle para usar lo que has aprendido para crear un modelo para clasificar las reseñas de Amazon como negativas o positivas. Los desafíos adicionales surgen de tener un conjunto de datos muy pequeño y desequilibrado en español.\n",
        "* [GPT-2](https://github.com/teticio/aventuras-con-textos/blob/master/GPT2.py). Un script de Python que utiliza la implementación PyTorch de Hugging Face para generar texto con el modelo GPT-2 de 1.500 millones de parámetros lanzado por [OpenAI](https://openai.com/blog/gpt-2-1-5b-release/) en noviembre de 2019.\n",
        "\n",
        "Todos los notebooks se pueden ejecutar en [Google Colab] (https://colab.research.google.com/github/teticio/aventuras-con-textos). Si quieres acceder a los *checkpoints* previamente entrenados (aproximadamente 10 Gb) en Google Colab, envía este [enlace] (https://drive.google.com/drive/folders/1QB6Pr5U1AUQMtk-GzHLa6ijJXiagsS4r?usp=sharing) a tu cuenta de Gmail y guarda el directorio con el nombre \"checkpoints\" en tu Google Drive en un subdirectorio (que puede ser necesario crear) llamado \"Cuadernos Colab\". Ten en cuenta que los notebooks actualmente funcionan con TensorFlow 1.14 y los puntos de control son compatibles con Keras 2.2.4. En Google Colab se pueden con `!pip uninstall -y tensorflow`,\n",
        "`!pip install --upgrade tensorflow-gpu==1.14` y `!pip install --upgrade keras==2.2.4`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXLOPC64rRe8",
        "lang": "en"
      },
      "source": [
        "This is a set of Jupyter notebooks I have created (in both Spanish and English) to accompany classes I give in Masters in Artificial Intelligence on the latest developments in end-to-end NLP (Natural Language Processing) with neural networks.\n",
        "<!--more-->\n",
        "\n",
        "Some people say that 2018 was the \"ImageNet\" year for text. By this they are referring to the breakthroughs in image recognition and, in particular, *transfer learning*. That is to say, the possibility of training a large, computationally expensive model on a general data set, and being able to \"fine-tune\" this model for a specific task (for example, to tell the difference between dogs and cats). Up until recently, it has not been feasible to apply transfer learning to text based (or NLP) models.\n",
        "\n",
        "* [References](https://github.com/teticio/aventuras-con-textos/blob/master/Referencias.ipynb). A list of links to all the relevant academic papers.\n",
        "* [Classification of text with cutting edge models](https://github.com/teticio/aventuras-con-textos/blob/master/Clasificacion_de_texto_con_modelos_de_ultima_generacion.ipynb). An introduction to and comparison of Word2Vec, ELMo, BERT and XLNet models for classifying IMDB movie reviews as either positive or negative.\n",
        "* [Attention](https://github.com/teticio/aventuras-con-textos/blob/master/Atencion.ipynb). A deep dive into the attention mechanism used in the Transformer - the main building block of BERT - starting from a simple Vec2Vec model to translate from English to Spanish.\n",
        "* [BERT understands](https://github.com/teticio/aventuras-con-textos/blob/master/BERT_entiende.ipynb). Here we use a BERT model that has been fine-tuned on the SQuAD (Stanford Question Answering Dataset) to answer reading comprehension questions about a Harry Potter book.\n",
        "* [BERT predicts](https://github.com/teticio/aventuras-con-textos/blob/master/BERT_predice.ipynb). BERT is trained to be able to fill in the missing words in a sentence.\n",
        "* [Bertle](https://github.com/teticio/aventuras-con-textos/blob/master/Bertle.ipynb). A semantic search engine that uses BERT sentence embeddings to find relevant articles from Stack Overflow.\n",
        "* [Dr BERT](https://github.com/teticio/aventuras-con-textos/blob/master/Dr_Bert.ipynb). A psychoanalyst inspired by [Eliza](http://psych.fullerton.edu/mbirnbaum/psych101/Eliza.htm) and trained using the transcripts of Dr Carl Rogers.\n",
        "* [Language models](https://github.com/teticio/aventuras-con-textos/blob/master/Modelos_de_lenguaje.ipynb). A language model is a function that estimates the probability of the next word (or *token*) conditioned on the text that precedes it. Here we are going to use the GPT-2 language model to predict the continuation of a sentence and to draw attention to unlikely constructions.\n",
        "* [Text generation with cutting edge models](https://github.com/teticio/aventuras-con-textos/blob/master/Modelos_generativos_de_texto_de_ultima_generacion.ipynb). Language Models XLNet and GPT-2 are used to generate random prose, from writing chapters of Game of Thrones to generating tweets in the style of Donald [Trump](/trumpy/).\n",
        "* [Amazon opinions](https://github.com/teticio/aventuras-con-textos/blob/master/Amazon_Opiniones.ipynb). A Kaggle style competition to use what you have learned to create a model to classify Amazon reviews as either negative or positive. Extra challenges arise from having a very small, unbalanced data set in Spanish.\n",
        "* [GPT-2](https://github.com/teticio/aventuras-con-textos/blob/master/GPT2.py). A Python script using Hugging Face's PyTorch implementation to generate text with the 1.5 billion parameter GPT-2 model released by [OpenAI](https://openai.com/blog/gpt-2-1-5b-release/) in November 2019.\n",
        "\n",
        "All the notebooks can be run on [Google Colab](https://colab.research.google.com/github/teticio/aventuras-con-textos). If you want to access the pre-trained checkpoints (approximately 10 Gb) on Google Colab, send this [link](https://drive.google.com/drive/folders/1QB6Pr5U1AUQMtk-GzHLa6ijJXiagsS4r?usp=sharing) to your Gmail account and save the directory with the name \"checkpoints\" to your Google Drive in a subdirectory (which you may need to create) called \"Colab Notebooks\". Note that the notebooks currently work with TensorFlow 1.14 and the checkpoints are compatible with Keras 2.2.4. On Google Colab you can install these with `!pip uninstall -y tensorflow`,\n",
        "`!pip install --upgrade tensorflow-gpu==1.14` and `!pip install --upgrade keras==2.2.4`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvvoWOdMrRe9"
      },
      "outputs": [],
      "source": [
        "# ejecuta esto en cada instancia de Google Colab antes de abrir los notebooks\n",
        "# run this in each instance of Google Colab before opening the notebooks\n",
        "!pip uninstall -y tensorflow\n",
        "!pip install --upgrade tensorflow-gpu==1.14\n",
        "\n",
        "# sólo necesario para poder cargar los checkpoints preentrenados\n",
        "# only needed to be able to load the pre-trained checkpoints \n",
        "!pip install --upgrade keras==2.2.4"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of README.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "nbTranslate": {
      "displayLangs": [
        "es",
        "en"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "es",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}